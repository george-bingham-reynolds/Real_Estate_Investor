{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2e6cf-9d5c-447a-82d5-5153a9353276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "from sklearn import linear_model as lm, metrics, ensemble as ens\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade7d23-a45c-4ba1-a796-0f3e748a3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"full_info.csv\")\n",
    "\n",
    "df_latest = pd.read_csv(\"latest_years.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb16fc-3f34-4ebc-a797-a28d94a6e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opzones = pd.read_csv(\"opzone_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b1ab1-4b52-4ce3-ae2c-abb10b31d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, prefix = 'state', columns = ['state'])\n",
    "df_latest = pd.get_dummies(df_latest, prefix = 'state', columns = ['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b282946-3e7c-4dda-b1b5-d89d46d94bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if 'state' in col:\n",
    "        df[col] = df[col].apply(lambda x: 1 if x == True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f3491-6516-48f2-9f2e-0df16a26f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest = df_latest[df_latest['year'] == df_latest['year'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4009bab3-c690-4c55-a0ad-259414fb7f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opzones = list(set(df_opzones['County'].values.tolist()))\n",
    "opzones_formatted = [x for x in df_latest['place'] if any(y in x for y in opzones)]\n",
    "df_latest = df_latest[df_latest['place'].isin(opzones_formatted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d384e-ca9e-4127-ab0e-f293fee80e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean current value: ', df_latest['average_home_value'].mean())\n",
    "print('median current value: ', df_latest['average_home_value'].median())\n",
    "print('25th percentile current value: ', np.percentile(df_latest['average_home_value'], 25))\n",
    "print('number 200k or less: ', len(df_latest[df_latest['average_home_value'] <= 200000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b805c7-94f2-4f9f-ae5a-8050679faa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest_candidates = df_latest.sort_values(by = 'average_home_value').drop(columns = [x for x in df_latest.columns if x != 'place' and\\\n",
    "                                        x != 'year' and x != 'average_annual_rent' and\\\n",
    "                                        x != 'average_home_value' and x != 'total_population' and \\\n",
    "                                                                                        # '3' not in x and\\\n",
    "                                        'roi' not in x and 'vacancy' not in x])\n",
    "\n",
    "df_latest_candidates = df_latest_candidates[~df_latest_candidates['place'].str.contains('California')]\n",
    "df_latest_candidates = df_latest_candidates[~df_latest_candidates['place'].str.contains('New York')]\n",
    "df_latest_candidates = df_latest_candidates[~df_latest_candidates['place'].str.contains('Puerto Rico')]\n",
    "df_latest_candidates = df_latest_candidates[~df_latest_candidates['place'].str.contains('Hawaii')]\n",
    "df_latest_candidates = df_latest_candidates[df_latest_candidates['average_home_value'] <= 250000]\n",
    "df_latest_candidates = df_latest_candidates[df_latest_candidates['total_population'] >= 100000]\n",
    "df_latest_candidates = df_latest_candidates[df_latest_candidates['vacancy_growth_last_1_years'] < 0]\n",
    "df_latest_candidates = df_latest_candidates[df_latest_candidates['vacancy_growth_last_3_years'] < df_latest_candidates['vacancy_growth_last_2_years']]\n",
    "df_latest_candidates = df_latest_candidates[df_latest_candidates['vacancy_growth_last_2_years'] < df_latest_candidates['vacancy_growth_last_1_years']] \n",
    "df_latest_candidates.sort_values(by = 'vacancy_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6975626-3e1d-4aed-ad12-ff3d53b8ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_latest['average_home_value'], bins = 35)\n",
    "plt.title(\"Average Home Value Distribution\")\n",
    "plt.xlabel(\"Value (in millions)\")\n",
    "plt.ylabel(\"Number of Counties\")\n",
    "plt.savefig(\"Home_Values_Dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e47b2d-5fc9-4ad5-81cb-f43d5323aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest['vacancy_rate'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9efba-b8c5-4bcd-8e61-c79ea741dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_latest['vacancy_rate'], bins = 50)\n",
    "plt.axvline(df_latest['vacancy_rate'].mean(), color = 'r', linestyle = 'dashed', label = 'Mean Vacancy Rate')\n",
    "plt.axvline(df_latest_candidates['vacancy_rate'].mean(), color = 'k', linestyle = 'dashed', label = 'Candidate Mean Vacancy Rate')\n",
    "plt.legend()\n",
    "plt.title(\"Vacancy Rate Distribution\")\n",
    "plt.xlabel(\"Vacancy Rate\")\n",
    "plt.ylabel(\"Number of Counties\")\n",
    "plt.savefig(\"Vacancy_Dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f079d-f137-4617-9842-fd0326997e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean current vacancy rate: ', df_latest['vacancy_rate'].mean())\n",
    "print('median current vacancy rate: ', df_latest['vacancy_rate'].median())\n",
    "print('25th percentile current vacancy rate: ', np.percentile(df_latest['vacancy_rate'], 25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca353a-bd79-4c93-a751-b5ca9b50c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_latest[df_latest['vacancy_rate'] < 0.2]['vacancy_rate'], bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f0ee5-14b3-4486-a971-703a5b2c1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE VALI DATA SECOND TO LAST YEAR; TEST DATA LAST YEAR; TRAIN FIRST 6\n",
    "last_year = df['year'].max()\n",
    "train = df[df['year'] < last_year - 4]\n",
    "vali = df[df['year'] == last_year - 1]\n",
    "test = df[df['year'] == last_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c559185-813a-4b5c-8065-d3a5c3dedd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training sample - ', len(train))\n",
    "print('validation sample - ', len(vali))\n",
    "print('test sample - ', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4653263-bf51-4b61-b7a9-5d79e905bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE NON-PERCENTAGES\n",
    "std_scl = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7d251-1365-461c-b6f6-bd6da373af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, Y SPLITS\n",
    "ex_train = train.drop(columns = ['year', 'place', 'roi'])\n",
    "ex_train_scaled = std_scl.fit_transform(ex_train)\n",
    "why_train = train['roi']\n",
    "\n",
    "\n",
    "ex_vali = vali.drop(columns = ['year', 'place', 'roi'])\n",
    "ex_vali_scaled = std_scl.fit_transform(ex_vali)\n",
    "why_vali = vali['roi']\n",
    "\n",
    "ex_test = test.drop(columns = ['year', 'place', 'roi'])\n",
    "ex_test_scaled = std_scl.fit_transform(ex_test)\n",
    "why_test = test['roi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e92fe",
   "metadata": {},
   "source": [
    "LET'S SET SOME \"DUMB\" BASELINES; A VERY SIMPLE MODEL AND STANDARD DEV (THIS ONE SHOULD BE HARDER SINCE WE DON'T KNOW AVERAGE OF POPULATION BEFOREHAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36113b-4b53-4248-b63d-3d8c9a5b3a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = metrics.mean_squared_error\n",
    "mae = metrics.mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf18ab-576d-43ca-8adf-edba9100d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('actuals mean - ', why_vali.mean())\n",
    "print('actuals standard dev - ', why_vali.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be781d-6272-4335-8bb0-9b86d8583051",
   "metadata": {},
   "outputs": [],
   "source": [
    "vali['average_home_value'] = vali['average_home_value'].astype('float')\n",
    "vali['home_val_growth_last_3_years'] = vali['home_val_growth_last_3_years'].astype('float')\n",
    "vali['average_annual_rent'] = vali['average_annual_rent'].astype('float')\n",
    "vali['rent_growth_last_1_years'] = vali['rent_growth_last_1_years'].astype('float')\n",
    "vali['rent_growth_last_2_years'] = vali['rent_growth_last_2_years'].astype('float')\n",
    "vali['rent_growth_last_3_years'] = vali['rent_growth_last_3_years'].astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf3d80-3c88-4f93-86f5-4469ad5d9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "vali['fake_pred'] = round(((vali['average_home_value'] * (1 + vali['home_val_growth_last_3_years']) - vali['average_home_value']) + \\\n",
    "                     (\n",
    "                        vali['average_annual_rent'] * (1 + vali['rent_growth_last_1_years']) +\\\n",
    "                        vali['average_annual_rent'] * (1 + vali['rent_growth_last_2_years']) +\\\n",
    "                        vali['average_annual_rent'] * (1 + vali['rent_growth_last_3_years'])\n",
    "                     ))/vali['average_home_value'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c0853-6d9c-4f03-9ca1-7d860f41a4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rmse - ', m.sqrt(mse(why_vali, vali['fake_pred'])))\n",
    "print('mae - ', mae(why_vali, vali['fake_pred']))\n",
    "vali = vali.drop(columns = ['fake_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a4f2a",
   "metadata": {},
   "source": [
    "START W/ OUT OF THE BOX PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986aae1-dab3-4938-a06c-c3738da4ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ens.RandomForestRegressor()\n",
    "# TRAIN/VALI\n",
    "rf_fit = rf.fit(ex_train, why_train)\n",
    "rf_preds = rf_fit.predict(ex_vali)\n",
    "print('rmse - ', m.sqrt(mse(why_vali, rf_preds)))\n",
    "print('mae - ', mae(why_vali, rf_preds))\n",
    "\n",
    "# # PERFORMANCE BEEN BAD SO WANNA SHPEEP TRAINING SCORES TOO - ARE WE OVER OR UNDER FITTING?\n",
    "rf_train_preds = rf.fit(ex_train, why_train).predict(ex_train)\n",
    "print('training rmse - ', m.sqrt(mse(why_train, rf_train_preds)))\n",
    "print('training mae - ', mae(why_train, rf_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a367fdca-96f1-4840-bab2-4da916f00dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ex_train.columns\n",
    "importances = rf_fit.feature_importances_\n",
    "data = {'feature_names': feature_names, 'feature_importance': importances}\n",
    "rf_df = pd.DataFrame(data)\n",
    "rf_df.sort_values(by = ['feature_importance'], ascending = False, inplace = True)\n",
    "rf_df = rf_df.head(20)\n",
    "\n",
    "sns.barplot(x = rf_df['feature_importance'], y = rf_df['feature_names'], ci = None)\n",
    "\n",
    "#ADD CHART LABELS\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature Names')\n",
    "# plt.savefig(\"adaboost_fi_diag_chrom_level\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea888e6d",
   "metadata": {},
   "source": [
    "VERSUS HYPERPARAMATER TUNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221816d-28e6-4e73-89f6-00d3f6a199e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r rf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed20d09-ad91-42ea-b891-20e06cea7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c9b3c-ab90-4081-a99c-9a71a8b4b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum([1 if 'pca__' in x else 0 for x in rf_params]) > 0:\n",
    "    steps = [('pca', PCA(n_components = rf_params['pca__n_components'])), \n",
    "             ('rf', ens.RandomForestRegressor(n_estimators = rf_params['rf__n_estimators'], \n",
    "                                          max_depth = rf_params['rf__max_depth'],\n",
    "                                          criterion = rf_params['rf__criterion']))]\n",
    "    model_rf = Pipeline(steps = steps)\n",
    "\n",
    "    \n",
    "    \n",
    "else:\n",
    "    \n",
    "    model_rf = ens.RandomForestRegressor(n_estimators = rf_params['n_estimators'], \n",
    "                                          max_depth = rf_params['max_depth'],\n",
    "                                          criterion = rf_params['criterion'])\n",
    "    \n",
    "# TRAIN/VALI\n",
    "rf_fit = model_rf.fit(ex_train, why_train)\n",
    "rf_preds_tuned = rf_fit.predict(ex_vali)\n",
    "print('rmse - ', m.sqrt(mse(why_vali, rf_preds_tuned)))\n",
    "print('mae - ', mae(why_vali, rf_preds_tuned))\n",
    "\n",
    "# PERFORMANCE BEEN BAD SO WANNA SHPEEP TRAINING SCORES TOO - ARE WE OVER OR UNDER FITTING?\n",
    "rf_train_preds_tuned = model_rf.fit(ex_train, why_train).predict(ex_train)\n",
    "print('training rmse - ', m.sqrt(mse(why_train, rf_train_preds_tuned)))\n",
    "print('training mae - ', mae(why_train, rf_train_preds_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e8945-b2e8-4e6e-93cc-f74af370a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r ada_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7377d8-f122-4e2a-9c1f-dea37cfc4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum([1 if 'pca__' in x else 0 for x in ada_params]) > 0:\n",
    "    steps = [('pca', PCA(n_components = ada_params['pca__n_components'])), \n",
    "             ('ada', ens.AdaBoostRegressor(n_estimators = ada_params['ada__n_estimators'], \n",
    "                                           learning_rate = ada_params['ada__learning_rate']))]\n",
    "             \n",
    "    ada = Pipeline(steps = steps)\n",
    "    \n",
    "else:\n",
    "    ada = ens.AdaBoostRegressor(n_estimators = ada_params['n_estimators'], \n",
    "                                learning_rate = ada_params['learning_rate'])\n",
    "\n",
    "    \n",
    "    \n",
    "# TRAIN/VALI\n",
    "ada_fit = ada.fit(ex_train, why_train)\n",
    "ada_preds = ada_fit.predict(ex_vali)\n",
    "print('rmse - ', m.sqrt(mse(why_vali, ada_preds)))\n",
    "print('mae - ', mae(why_vali, ada_preds))\n",
    "               \n",
    "# PERFORMANCE BEEN BAD SO WANNA SHPEEP TRAINING SCORES TOO - ARE WE OVER OR UNDER FITTING?\n",
    "ada_train_preds = ada.fit(ex_train, why_train).predict(ex_train)\n",
    "print('training rmse - ', m.sqrt(mse(why_train, ada_train_preds)))\n",
    "print('training mae - ', mae(why_train, ada_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a8509-eadd-4847-8073-b674971ea038",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum([1 if 'pca__' in x else 0 for x in ada_params]) == 0:\n",
    "    feature_names = ex_train.columns\n",
    "    importances = ada_fit.feature_importances_\n",
    "    data = {'feature_names': feature_names, 'feature_importance': importances}\n",
    "    ada_df = pd.DataFrame(data)\n",
    "    ada_df.sort_values(by = ['feature_importance'], ascending = False, inplace = True)\n",
    "    ada_df = ada_df.head(20)\n",
    "\n",
    "    sns.barplot(x = ada_df['feature_importance'], y = ada_df['feature_names'], ci = None)\n",
    "\n",
    "    #ADD CHART LABELS\n",
    "    plt.title('AdaBoost Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')\n",
    "    # plt.savefig(\"adaboost_fi_diag_chrom_level\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b479b52-aef3-4a69-a3ef-1a332dcc4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r xgboost_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20dd22e-1f47-495a-bdea-00fceaaf9918",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df570f56-a3c6-4d0b-b00e-3c7afa2ff25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST IS BEING A CRYBABY ABOUT TYPES IDK WHY, BUT WHATEVER I'LL EXPLICITLY FIX LOL\n",
    "ex_train['average_annual_rent'] = ex_train['average_annual_rent'].astype(float)\n",
    "ex_train['average_home_value'] = ex_train['average_home_value'].astype(float)\n",
    "ex_train['average_income'] = ex_train['average_income'].astype(float)\n",
    "\n",
    "ex_vali['average_annual_rent'] = ex_vali['average_annual_rent'].astype(float)\n",
    "ex_vali['average_home_value'] = ex_vali['average_home_value'].astype(float)\n",
    "ex_vali['average_income'] = ex_vali['average_income'].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "if sum([1 if 'pca__' in x else 0 for x in xgboost_params]) > 0:\n",
    "    steps = [('pca', PCA(n_components = xgboost_params['pca__n_components'])), \n",
    "             ('xg', XGBRegressor(scale_pos_weight = xgboost_params['xg__scale_pos_weight'],\n",
    "                                  max_depth = xgboost_params['xg__max_depth'], \n",
    "                                  eta = xgboost_params['xg__eta']))]\n",
    "             \n",
    "    xg = Pipeline(steps = steps)\n",
    "    \n",
    "else:\n",
    "    xg = XGBRegressor(scale_pos_weight = xgboost_params['scale_pos_weight'],\n",
    "                  max_depth = xgboost_params['max_depth'], \n",
    "                  eta = xgboost_params['eta'])\n",
    "\n",
    "# TRAIN/VALI\n",
    "xg_fit = xg.fit(ex_train, why_train)\n",
    "xg_preds = xg_fit.predict(ex_vali)\n",
    "print('rmse - ', m.sqrt(mse(why_vali, xg_preds)))\n",
    "print('mae - ', mae(why_vali, xg_preds))\n",
    "\n",
    "# PERFORMANCE BEEN BAD SO WANNA SHPEEP TRAINING SCORES TOO - ARE WE OVER OR UNDER FITTING?\n",
    "xg_train_preds = xg.fit(ex_train, why_train).predict(ex_train)\n",
    "print('training rmse - ', m.sqrt(mse(why_train, xg_train_preds)))\n",
    "print('training mae - ', mae(why_train, xg_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f74dc-b671-4004-b7a8-6e11f84c0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum([1 if 'pca__' in x else 0 for x in xgboost_params]) == 0:\n",
    "    feature_names = ex_train.columns\n",
    "    importances = xg_fit.feature_importances_\n",
    "    data = {'feature_names': feature_names, 'feature_importance': importances}\n",
    "    xg_df = pd.DataFrame(data)\n",
    "    xg_df.sort_values(by = ['feature_importance'], ascending = False, inplace = True)\n",
    "    xg_df = xg_df.head(20)\n",
    "\n",
    "    sns.barplot(x = xg_df['feature_importance'], y = xg_df['feature_names'], ci = None)\n",
    "\n",
    "    #ADD CHART LABELS\n",
    "    plt.title('XGBoost Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')\n",
    "    # plt.savefig(\"adaboost_fi_diag_chrom_level\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401b2a2-77be-4ef4-a476-d8af6a489ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO MODEL PERFORMANCE NOT GREAT, BUT I WANNA SEE WHAT THE TOP PREDICTED AREAS WERE FOR FUN\n",
    "# AFTER ALL, IF IT'S TYPICALLY OFF BUT THE VERY HIGH PREDS ARE MORE SOLID, THEN THIS ACTUALLY IS STILL USEFUL\n",
    "# SINCE OUR GOAL IS TO USE THIS TO IDENTIFY TOP CANDIDATES\n",
    "# RF WAS MOST PERFORMANT SO GOING TO BASE THIS ON THOSE PREDS\n",
    "\n",
    "vali['predicted_roi'] = rf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dce8d3-4a0e-4368-b169-3a89424d2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_check = vali.sort_values(by = 'predicted_roi', ascending = False)\n",
    "pred_check = pred_check.drop(columns = [x for x in df.columns if x != 'place' and\\\n",
    "                                        x != 'year' and x != 'average_annual_rent' and\\\n",
    "                                        x != 'average_home_value' and x != 'total_population' and\\\n",
    "                                        'roi' not in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c0237-fb33-4b82-bbcb-6ec73fd5faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ec = vali.copy()\n",
    "df_ec['error'] = round(df_ec['predicted_roi'] - df_ec['roi'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d8ef4-f8e8-4b6d-8ddd-bb34094dfbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_ec['error'], bins = 30)\n",
    "plt.title(\"Residual Distribution \\nValidation Data\")\n",
    "plt.xlabel(\"Size of Error\")\n",
    "plt.ylabel(\"Number of Observations\")\n",
    "plt.savefig(\"Model_Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6e9850",
   "metadata": {},
   "source": [
    "CHECKING IN, NONE OF THE MODELS (OFF THE SHELF OR TUNED) ACTUALLY BEAT THE STANDARD DEVIATION OF THE VALIDATION SET'S ROI. THIS MEANS NONE DOES BETTER THAN PREDICTING THE SET'S AVERAGE (THIS IS HARDER THAN IT SOUNDS AS WE DON'T HAVE THE AVERAGE AHEAD OF TIME). THIS LEADS ME TO CONCLUDE THE MODELS ARE OK IF IMPERFECT. THIS SEEMS TO BE IN LINE WITH THE MODEL ERROR BEING FAIRLY NORMAL BUT NOT QUITE ABOUT ZERO.\n",
    "\n",
    "NEXT, WE CHECK WITH A MORE \"REAL WORLD\" TEST. REALISTICALLY WE WOULD NOT BE BUYING AND SHORTING ON EVERY CITY'S REAL ESTATE MARKET, SO THE BETTER APPLICATION IS TO SEE WHAT WOULD HAVE HAPPENED IF WE HAD USED THE MODEL TO IDENTIFY TOP CANDIDATES IN THE LATEST YEAR OF TESTABLE DATA. I CONSIDER ANY CANDIDATE IDENTIFIED THAT WOULD HAVE PERFORMED BETTER THAN AVERAGE ACCEPTABLE (THRESHOLD IN CELL BELOW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predicted roi mean - ', pred_check['predicted_roi'].mean())\n",
    "print('roi mean - ', pred_check['roi'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af6691-1171-4bc4-b712-d1741af6598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opzones = list(set(df_opzones['County'].values.tolist()))\n",
    "opzones_formatted = [x for x in pred_check['place'] if any(y in x for y in opzones)]\n",
    "pred_check = pred_check[pred_check['place'].isin(opzones_formatted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ef6e8-4b3f-44b5-a9a4-31804673b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_check.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e11ce4-cbc5-42a3-b0d2-1f8f3d271d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_check.sort_values(by = 'roi', ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11950e15-68c7-4c7d-9d4d-b52b389fe091",
   "metadata": {},
   "outputs": [],
   "source": [
    "[place for place in pred_check.head(25)['place'].values.tolist() if \\\n",
    " place in pred_check.sort_values(by = 'roi', ascending = False).head(25)['place'].values.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b114f",
   "metadata": {},
   "source": [
    "SO, 6 OUT OF 25 OF THE TOP IDENTIFIED CANDIDATES WOULD HAVE PERFORMED WORSE THAN AVERAGE, 6 OF THE TOP 25 PERFORMERS WOULD HAVE HAD BELOW AVERAGE PREDICTIONS, AND 1 COUNTY WOULD HAVE BEEN TOP 25 IN EACH. USING THIS TEST OF THE MODEL IT IS CLEAR THAT IT CAN BE USEFUL (THE MAJORITY OF ITS TOP PREDICTIONS WOULD HAVE BEEN ABOVE AVERAGE, AND THE MAJORITY OF THE TOP PERFORMERS WOULD HAVE BEEN PREDICTED ABOVE AVERAGE) BUT WOULD HAVE TO BE USED WITH GREAT CAUTION IN A REAL-WORLD INVESTMENT SETTING, GIVEN THAT ROUGHLY A QUARTER OF THE TIME ITS RECOMMENDATION WOULD HAVE DONE QUITE POORLY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b878c-fdc6-4ae1-bcd9-bf62a8cbc38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_total = pd.concat([pd.concat([ex_train, ex_vali]), ex_test])\n",
    "why_total = pd.concat([pd.concat([why_train, why_vali]), why_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137b31f-064b-4cfc-a708-0eccaf811bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest = df_latest.dropna()\n",
    "ex_serving = df_latest.drop(columns = ['year', 'place'])\n",
    "ex_serving_scaled = std_scl.fit_transform(ex_serving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6be23-4542-4957-a548-1d82670d65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_serve = rf.fit(ex_total, why_total)\n",
    "rf_preds = rf_serve.predict(ex_serving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb573a45-9676-4ac5-ae34-06ceacadef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latest['pred'] = rf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff163d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE PLACE EASIER FOR API I.E. NO SPACES; WANNA KEEP IN ORIGINAL DF IN CASE I WANT FURTHER ANALYSIS\n",
    "df_save = df_latest.copy()\n",
    "df_save['place'] = df_save['place'].apply(lambda x: re.sub(' ', '.', \n",
    "                                                           re.sub('St.', 'Saint', \n",
    "                                                                  re.sub(' - ', '.', x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO NEED TO KEEP STATE DUMMIES FOR API; STATE ALREADY HUMAN-READABLE WITH PLACE COLUMN\n",
    "df_save = df_save.drop(columns = [x for x in df_save.columns if 'state_' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5064a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save.to_csv(\"latest_yrs_w_preds_county.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50befc05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
